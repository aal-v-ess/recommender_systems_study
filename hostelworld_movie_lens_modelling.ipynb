{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pathlib import Path\n",
    "import time\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from typing import List, Dict, Tuple, Set\n",
    "import json\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadData:\n",
    "    def __init__(self, data_path: Optional[str] = None, feedback_store: Optional[str] = None):\n",
    "        # Initialize feedback storage\n",
    "        self.feedback_store = feedback_store or 'recommendation_data/feedback.csv'\n",
    "        self.data_path = data_path or 'clean_movies_data.csv'\n",
    "        self._init_feedback_store()\n",
    "\n",
    "    def _init_feedback_store(self):\n",
    "        \"\"\"Initialize feedback storage\"\"\"\n",
    "        if not Path(self.feedback_store).exists():\n",
    "            pd.DataFrame(columns=[\n",
    "                'user_id', 'item_id', 'rating', 'user_movie_tags', 'timestamp', 'recommendation_type'\n",
    "            ]).to_csv(self.feedback_store, index=False)\n",
    "\n",
    "    def _read_movies_data(self):\n",
    "        \"\"\"Read movies data\"\"\"\n",
    "        df_return = pd.read_csv(self.data_path)\n",
    "        df_return.columns = ['user_id', 'item_id', 'rating', 'user_movie_tags', 'title', 'genres', 'year']\n",
    "        return df_return\n",
    "    \n",
    "    def _read_feedback_data(self):\n",
    "        return pd.read_csv(self.feedback_store)\n",
    "    \n",
    "    def _cat_ids(self, df: pd.DataFrame, id: str) -> pd.DataFrame:\n",
    "        \"\"\"Categorize user and item ids.\"\"\"\n",
    "        df[id] = pd.Categorical(df[id])\n",
    "        df[id] = df[id].cat.codes\n",
    "        return df\n",
    "    \n",
    "    def read_and_update_data(self):\n",
    "        if len(self._read_feedback_data()) == 0:\n",
    "            df_return = self._read_movies_data()\n",
    "            df_return = self._cat_ids(df_return, 'user_id')\n",
    "            df_return = self._cat_ids(df_return, 'item_id')\n",
    "            return df_return\n",
    "        else:\n",
    "            df_movies = self._read_movies_data()\n",
    "            df_feedback = self._read_feedback_data()    \n",
    "            df_feedback_enriched = pd.merge(df_feedback.drop(columns=['timestamp', 'recommendation_type']), \n",
    "                                            df_movies[['item_id', 'title', 'genres', 'year']], \n",
    "                                            on='item_id', \n",
    "                                            how='left').drop_duplicates()\n",
    "            df_return = pd.concat([df_movies, df_feedback_enriched], ignore_index=True)\n",
    "            df_return = self._cat_ids(df_return, 'user_id')\n",
    "            df_return = self._cat_ids(df_return, 'item_id')\n",
    "            return df_return\n",
    "        \n",
    "    def transform_items_df(df):\n",
    "        df_items = df[['item_id', 'title', 'genres', 'year', 'user_movie_tags']].copy()\n",
    "        tag_counts = df_items.groupby('item_id')['user_movie_tags'].agg(lambda x: dict(Counter(x))).reset_index()\n",
    "        unique_movies = df_items.drop_duplicates(subset=['item_id']).drop(columns=['user_movie_tags'])\n",
    "        df_return = pd.merge(unique_movies, tag_counts, on='item_id')\n",
    "        return df_return\n",
    "    \n",
    "    def transform_user_df(df):\n",
    "        \"\"\"Transform user interactions into aggregated user profiles.\"\"\"\n",
    "        df_user = df[['user_id', 'item_id', 'rating', 'user_movie_tags']].copy()\n",
    "        user_profiles = {}\n",
    "        for user_id in df_user['user_id'].unique():\n",
    "            user_data = df_user[df_user['user_id'] == user_id]\n",
    "            \n",
    "            # Aggregate ratings\n",
    "            rating_stats = {\n",
    "                'avg_rating': user_data['rating'].mean(),\n",
    "                'rating_std': user_data['rating'].std(),\n",
    "                'num_ratings': len(user_data),\n",
    "                'rating_distribution': dict(Counter(user_data['rating']))\n",
    "            }\n",
    "            \n",
    "            # Aggregate movie tags\n",
    "            tag_counts = dict(Counter(user_data['user_movie_tags'].explode()))\n",
    "            \n",
    "            # Create user profile\n",
    "            user_profiles[user_id] = {\n",
    "                'user_id': user_id,\n",
    "                'rating_stats': rating_stats,\n",
    "                'tag_preferences': tag_counts,\n",
    "                'rated_movies': user_data['item_id'].tolist()\n",
    "            }\n",
    "        \n",
    "        return pd.DataFrame.from_dict(user_profiles, orient='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ReadData().read_and_update_data()\n",
    "df.columns = ['user_id', 'item_id', 'rating', 'user_movie_tags', 'title', 'genres', 'year']\n",
    "items_df = ReadData.transform_items_df(df)\n",
    "user_interactions_df = ReadData.transform_user_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingGenerator:\n",
    "    def __init__(self):\n",
    "        # self.genre_vectorizer = TfidfVectorizer()\n",
    "        # self.tag_vectorizer = TfidfVectorizer()\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "        self.text_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        # self.scaler = MinMaxScaler()\n",
    "        self.genre_vectorizer = TfidfVectorizer()\n",
    "        self.tag_vectorizer = TfidfVectorizer()\n",
    "        \n",
    "    def _process_tag_dictionary(self, tag_dicts):\n",
    "        \"\"\"Convert list of tag dictionaries to a frequency matrix.\"\"\"\n",
    "        # Get all unique tags\n",
    "        all_tags = set()\n",
    "        for tag_dict in tag_dicts:\n",
    "            all_tags.update(tag_dict.keys())\n",
    "        all_tags = sorted(list(all_tags))\n",
    "        \n",
    "        # Create matrix of tag frequencies\n",
    "        tag_matrix = np.zeros((len(tag_dicts), len(all_tags)))\n",
    "        for i, tag_dict in enumerate(tag_dicts):\n",
    "            for j, tag in enumerate(all_tags):\n",
    "                tag_matrix[i, j] = tag_dict.get(tag, 0)\n",
    "        \n",
    "        # Normalize the frequencies\n",
    "        row_sums = tag_matrix.sum(axis=1, keepdims=True)\n",
    "        tag_matrix = np.divide(tag_matrix, row_sums, where=row_sums!=0)\n",
    "        \n",
    "        return tag_matrix\n",
    "    \n",
    "    def create_item_embeddings(self, items_df):\n",
    "        \"\"\"Generate embeddings for items using various features.\"\"\"\n",
    "        # 1. Generate text embeddings for titles\n",
    "        title_embeddings = self.text_model.encode(items_df['title'].tolist())\n",
    "        \n",
    "        # 2. Process genres\n",
    "        genre_embeddings = self.genre_vectorizer.fit_transform(items_df['genres']).toarray()\n",
    "        \n",
    "        # 3. Process year\n",
    "        years = self.scaler.fit_transform(items_df[['year']]).reshape(-1)\n",
    "        \n",
    "        # 4. Process movie tags - now using the dictionary format\n",
    "        tag_matrix = self._process_tag_dictionary(items_df['user_movie_tags'].tolist())\n",
    "        \n",
    "        # 5. Combine all embeddings\n",
    "        combined_embeddings = np.hstack([\n",
    "            title_embeddings,\n",
    "            genre_embeddings,\n",
    "            tag_matrix,\n",
    "            years.reshape(-1, 1)\n",
    "        ])\n",
    "        \n",
    "        return combined_embeddings\n",
    "    \n",
    "    def create_user_embeddings(self, user_profiles_df):\n",
    "        \"\"\"Generate embeddings for users based on their aggregated profiles.\"\"\"\n",
    "        \n",
    "        # 1. Process rating statistics\n",
    "        rating_features = np.column_stack([\n",
    "            user_profiles_df['rating_stats'].apply(lambda x: x['avg_rating']),\n",
    "            user_profiles_df['rating_stats'].apply(lambda x: x['rating_std']),\n",
    "            user_profiles_df['rating_stats'].apply(lambda x: x['num_ratings'])\n",
    "        ])\n",
    "        \n",
    "        # 2. Process tag preferences\n",
    "        # Create a vocabulary of all tags\n",
    "        all_tags = set()\n",
    "        for tags in user_profiles_df['tag_preferences']:\n",
    "            all_tags.update(tags.keys())\n",
    "        \n",
    "        # Create tag frequency matrix\n",
    "        tag_matrix = np.zeros((len(user_profiles_df), len(all_tags)))\n",
    "        for i, tags in enumerate(user_profiles_df['tag_preferences']):\n",
    "            for j, tag in enumerate(all_tags):\n",
    "                tag_matrix[i, j] = tags.get(tag, 0)\n",
    "        \n",
    "        # Normalize tag frequencies\n",
    "        tag_matrix = tag_matrix / (tag_matrix.sum(axis=1, keepdims=True) + 1e-10)\n",
    "        \n",
    "        # 3. Combine all features\n",
    "        user_embeddings = np.hstack([\n",
    "            rating_features,\n",
    "            tag_matrix\n",
    "        ])\n",
    "        \n",
    "        return user_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pedro Alves\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embedding_generator = EmbeddingGenerator()\n",
    "# Generate item embeddings\n",
    "item_embeddings = embedding_generator.create_item_embeddings(items_df)\n",
    "# Generate user embeddings\n",
    "user_embeddings = embedding_generator.create_user_embeddings(user_interactions_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedRecommendationPreComputer:\n",
    "    def __init__(self, \n",
    "                 items_df: pd.DataFrame,\n",
    "                 user_profiles_df: pd.DataFrame,\n",
    "                 user_embeddings: np.ndarray,\n",
    "                 item_embeddings: np.ndarray,\n",
    "                 user_feedback_df: Optional[pd.DataFrame] = None,\n",
    "                 user_demographic_df: Optional[pd.DataFrame] = None):\n",
    "        \"\"\"Initialize recommendation computer\"\"\"\n",
    "        self.items_df = items_df\n",
    "        self.user_profiles_df = user_profiles_df\n",
    "        self.user_embeddings = user_embeddings\n",
    "        self.item_embeddings = item_embeddings\n",
    "        self.user_feedback_df = user_feedback_df\n",
    "        self.user_demographic_df = user_demographic_df\n",
    "        \n",
    "        # Configuration\n",
    "        self.content_weight = 0.3\n",
    "        self.collaborative_weight = 0.7\n",
    "        self.diversity_weight = 0.05\n",
    "        self.base_score = 0.05\n",
    "        self.n_precomputed_recs = 100\n",
    "        self.similar_users = 20\n",
    "\n",
    "        # self.content_weight = 0.2\n",
    "        # self.collaborative_weight = 0.7\n",
    "        # self.diversity_weight = 0.05\n",
    "        # self.base_score = 0.05\n",
    "        # self.n_precomputed_recs = 100\n",
    "        # self.similar_users = 20\n",
    "        \n",
    "        # Calculate dimensions\n",
    "        self.user_tag_start = 3  # After rating stats (mean, std, count)\n",
    "        self.item_tag_start = 384 + 20  # After title embedding (384) and approximate genre embedding (20)\n",
    "        \n",
    "        # Initialize computations\n",
    "        self._compute_genre_representation()\n",
    "        self._compute_item_metrics()\n",
    "        \n",
    "        print(f\"User embedding shape: {self.user_embeddings.shape}\")\n",
    "        print(f\"Item embedding shape: {self.item_embeddings.shape}\")\n",
    "    \n",
    "    def compute_user_recommendations(self, user_idx: int) -> List[Dict]:\n",
    "        \"\"\"Compute recommendations for a single user with bias mitigation\"\"\"\n",
    "        # Get user profile\n",
    "        user_profile = self.user_profiles_df.iloc[user_idx]\n",
    "        \n",
    "        # 1. Get user components\n",
    "        user_tag_vector = self.user_embeddings[user_idx, self.user_tag_start:]\n",
    "        \n",
    "        # 2. Get item components\n",
    "        item_tag_vectors = self.item_embeddings[:, self.item_tag_start:-1]  # Exclude year\n",
    "        \n",
    "        # Calculate tag-based similarity only on tag portions\n",
    "        # Reshape both to 2D arrays for cosine_similarity\n",
    "        user_tag_vector_2d = user_tag_vector.reshape(1, -1)\n",
    "        min_dim = min(user_tag_vector_2d.shape[1], item_tag_vectors.shape[1])\n",
    "        \n",
    "        # Take only the common dimensions\n",
    "        tag_similarity = cosine_similarity(\n",
    "            user_tag_vector_2d[:, :min_dim],\n",
    "            item_tag_vectors[:, :min_dim]\n",
    "        )[0]\n",
    "        \n",
    "        # 3. Rating-based weighting\n",
    "        rating_stats = user_profile['rating_stats']\n",
    "        rating_weight = np.clip(rating_stats['avg_rating'] / 5.0, 0.5, 1.0)\n",
    "        \n",
    "        # 4. Genre diversity\n",
    "        diversity_scores = self._calculate_diversity_scores()\n",
    "        \n",
    "        # 5. Collaborative filtering scores\n",
    "        cf_scores = self._compute_collaborative_scores(user_idx)\n",
    "        \n",
    "        # Combine scores with weights\n",
    "        final_scores = (\n",
    "            self.content_weight * self._normalize_scores(tag_similarity) * rating_weight +\n",
    "            self.collaborative_weight * self._normalize_scores(cf_scores) +\n",
    "            self.diversity_weight * diversity_scores +\n",
    "            self.base_score  # Base score\n",
    "        )\n",
    "        \n",
    "        # Get top items\n",
    "        top_indices = np.argsort(final_scores)[::-1][:self.n_precomputed_recs]\n",
    "        \n",
    "        # Create recommendations\n",
    "        recommendations = []\n",
    "        for rank, idx in enumerate(top_indices):\n",
    "            recommendations.append({\n",
    "                'user_id': user_idx,\n",
    "                'item_id': self.items_df.index[idx],\n",
    "                'title': self.items_df.iloc[idx]['title'],\n",
    "                'genres': self.items_df.iloc[idx]['genres'],\n",
    "                'score': float(final_scores[idx]),\n",
    "                'rank': rank,\n",
    "                'recommendation_type': 'personalized'\n",
    "            })\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def _compute_collaborative_scores(self, user_idx: int) -> np.ndarray:\n",
    "        \"\"\"Compute collaborative filtering scores for a user\"\"\"\n",
    "        # Use only tag portions for user similarity\n",
    "        user_tag_vector = self.user_embeddings[user_idx, self.user_tag_start:]\n",
    "        all_user_tag_vectors = self.user_embeddings[:, self.user_tag_start:]\n",
    "        \n",
    "        # Calculate similarity using common dimensions\n",
    "        min_dim = min(user_tag_vector.shape[0], all_user_tag_vectors.shape[1])\n",
    "        user_similarities = cosine_similarity(\n",
    "            user_tag_vector[:min_dim].reshape(1, -1),\n",
    "            all_user_tag_vectors[:, :min_dim]\n",
    "        )[0]\n",
    "        \n",
    "        # Get top similar users (excluding self)\n",
    "        n_similar = self.similar_users\n",
    "        similar_users = np.argsort(user_similarities)[-n_similar-1:-1][::-1]\n",
    "        \n",
    "        # Calculate weighted sum of similar users' interactions\n",
    "        cf_scores = np.zeros(len(self.items_df))\n",
    "        \n",
    "        for sim_user in similar_users:\n",
    "            sim_score = user_similarities[sim_user]\n",
    "            sim_user_profile = self.user_profiles_df.iloc[sim_user]\n",
    "            \n",
    "            # Use rated movies\n",
    "            rated_movies = sim_user_profile['rated_movies']\n",
    "            for movie_id in rated_movies:\n",
    "                if movie_id in self.items_df.index:\n",
    "                    movie_idx = self.items_df.index.get_loc(movie_id)\n",
    "                    cf_scores[movie_idx] += sim_score\n",
    "        \n",
    "        return cf_scores\n",
    "\n",
    "    def _compute_genre_representation(self):\n",
    "        \"\"\"Compute genre representation metrics\"\"\"\n",
    "        # Compute genre counts\n",
    "        genre_counts = {}\n",
    "        for _, row in self.items_df.iterrows():\n",
    "            if isinstance(row['genres'], str):  # Ensure genres is a string\n",
    "                genres = row['genres'].split(',')\n",
    "                for genre in genres:\n",
    "                    genre = genre.strip()  # Remove any whitespace\n",
    "                    genre_counts[genre] = genre_counts.get(genre, 0) + 1\n",
    "        \n",
    "        # Calculate genre representation scores\n",
    "        total_items = len(self.items_df)\n",
    "        self.genre_representation = {\n",
    "            genre: count/total_items \n",
    "            for genre, count in genre_counts.items()\n",
    "        }\n",
    "        \n",
    "        # Identify underrepresented genres\n",
    "        mean_representation = np.mean(list(self.genre_representation.values()))\n",
    "        self.underrepresented_genres = {\n",
    "            genre: score \n",
    "            for genre, score in self.genre_representation.items()\n",
    "            if score < mean_representation\n",
    "        }\n",
    "    \n",
    "    def compute_cold_start_recommendations(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Compute generic recommendations for new users based on popularity and diversity\n",
    "        Returns DataFrame with cold start recommendations\n",
    "        \"\"\"\n",
    "        print(\"Computing cold-start recommendations...\")\n",
    "        \n",
    "        # Create a scoring DataFrame for all items\n",
    "        item_scores = pd.DataFrame(index=self.items_df.index)\n",
    "        \n",
    "        # Calculate popularity scores (if we have feedback data)\n",
    "        if hasattr(self, 'item_popularity'):\n",
    "            popularity_scores = self._normalize_series(self.item_popularity['mean'])\n",
    "        else:\n",
    "            # If no feedback data, use equal popularity\n",
    "            popularity_scores = pd.Series(1.0/len(self.items_df), index=self.items_df.index)\n",
    "        \n",
    "        # Calculate diversity scores\n",
    "        diversity_scores = self._calculate_diversity_scores()\n",
    "        \n",
    "        # Combine scores\n",
    "        item_scores['popularity'] = popularity_scores\n",
    "        item_scores['diversity'] = diversity_scores\n",
    "        item_scores['final_score'] = (\n",
    "            0.7 * item_scores['popularity'] +\n",
    "            0.3 * item_scores['diversity']\n",
    "        )\n",
    "        \n",
    "        # Get top recommendations\n",
    "        top_items = item_scores.nlargest(self.n_precomputed_recs, 'final_score')\n",
    "        \n",
    "        # Create recommendations records\n",
    "        cold_start_recs = []\n",
    "        for rank, (idx, row) in enumerate(top_items.iterrows()):\n",
    "            cold_start_recs.append({\n",
    "                'user_id': 'COLD_START',\n",
    "                'item_id': idx,\n",
    "                'title': self.items_df.loc[idx, 'title'],\n",
    "                'genres': self.items_df.loc[idx, 'genres'],\n",
    "                'score': row['final_score'],\n",
    "                'rank': rank,\n",
    "                'recommendation_type': 'cold_start'\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(cold_start_recs)\n",
    "    \n",
    "    def _compute_item_metrics(self):\n",
    "        \"\"\"Compute various item metrics for cold-start and bias mitigation\"\"\"\n",
    "        self.item_popularity = pd.DataFrame(index=self.items_df.index)\n",
    "        self.item_popularity['count'] = 1\n",
    "        self.item_popularity['mean'] = 0\n",
    "    \n",
    "    def _calculate_diversity_scores(self) -> pd.Series:\n",
    "        \"\"\"Calculate diversity scores for items based on genres\"\"\"\n",
    "        diversity_scores = []\n",
    "        \n",
    "        for _, item in self.items_df.iterrows():\n",
    "            if isinstance(item['genres'], str):  # Check if genres is a string\n",
    "                genres = item['genres'].split(',')\n",
    "                genres = [g.strip() for g in genres]  # Clean any whitespace\n",
    "                \n",
    "                # Higher score for underrepresented genres\n",
    "                genre_scores = []\n",
    "                for genre in genres:\n",
    "                    if genre in self.genre_representation:\n",
    "                        genre_scores.append(1/self.genre_representation[genre])\n",
    "                \n",
    "                diversity_scores.append(np.mean(genre_scores) if genre_scores else 0)\n",
    "            else:\n",
    "                diversity_scores.append(0)  # Default score for items without genres\n",
    "        \n",
    "        return pd.Series(diversity_scores, index=self.items_df.index)\n",
    "    \n",
    "    \n",
    "    def _normalize_series(self, series: pd.Series) -> pd.Series:\n",
    "        \"\"\"Normalize series to [0,1] range\"\"\"\n",
    "        min_val = series.min()\n",
    "        max_val = series.max()\n",
    "        if max_val == min_val:\n",
    "            return pd.Series(0, index=series.index)\n",
    "        return (series - min_val) / (max_val - min_val)\n",
    "\n",
    "    \n",
    "    def _normalize_scores(self, scores):\n",
    "        \"\"\"Normalize scores to range [0,1]\"\"\"\n",
    "        min_score = scores.min()\n",
    "        max_score = scores.max()\n",
    "        if max_score == min_score:\n",
    "            return np.zeros_like(scores)\n",
    "        return (scores - min_score) / (max_score - min_score)\n",
    "\n",
    "    def compute_all_recommendations(self, output_path: str = 'recommendation_data'):\n",
    "        \"\"\"Compute recommendations for all users plus cold-start\"\"\"\n",
    "        start_time = time.time()\n",
    "        Path(output_path).mkdir(exist_ok=True)\n",
    "        \n",
    "        print(\"Starting recommendation computation...\")\n",
    "        \n",
    "        # First, compute cold-start recommendations\n",
    "        cold_start_df = self.compute_cold_start_recommendations()\n",
    "        cold_start_df.to_csv(f'{output_path}/recommendations.csv', index=False)\n",
    "        print(f\"Saved {len(cold_start_df)} cold-start recommendations\")\n",
    "        \n",
    "        # Then compute personalized recommendations in batches\n",
    "        batch_size = 100\n",
    "        n_users = len(self.user_embeddings)\n",
    "        \n",
    "        print(f\"Computing personalized recommendations for {n_users} users...\")\n",
    "        for batch_start in range(0, n_users, batch_size):\n",
    "            batch_end = min(batch_start + batch_size, n_users)\n",
    "            print(f\"Processing users {batch_start} to {batch_end}...\")\n",
    "            \n",
    "            batch_recommendations = []\n",
    "            for user_idx in range(batch_start, batch_end):\n",
    "                user_recs = self.compute_user_recommendations(user_idx)\n",
    "                batch_recommendations.extend(user_recs)\n",
    "            \n",
    "            # Append batch to CSV\n",
    "            batch_df = pd.DataFrame(batch_recommendations)\n",
    "            batch_df.to_csv(\n",
    "                f'{output_path}/recommendations.csv', \n",
    "                mode='a', \n",
    "                header=False, \n",
    "                index=False\n",
    "            )\n",
    "        \n",
    "        computation_time = time.time() - start_time\n",
    "        print(f\"Completed recommendation computation in {computation_time:.2f} seconds\")\n",
    "        \n",
    "        # Save metadata\n",
    "        metadata = {\n",
    "            'computation_time': computation_time,\n",
    "            'n_users': n_users,\n",
    "            'n_items_per_user': self.n_precomputed_recs,\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'cold_start_items': len(cold_start_df),\n",
    "            'genre_representation': self.genre_representation\n",
    "        }\n",
    "        \n",
    "        pd.DataFrame([metadata]).to_json(f'{output_path}/metadata.json')\n",
    "        print(\"Saved computation metadata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User embedding shape: (611, 1072)\n",
      "Item embedding shape: (9700, 1478)\n",
      "Starting recommendation computation...\n",
      "Computing cold-start recommendations...\n",
      "Saved 100 cold-start recommendations\n",
      "Computing personalized recommendations for 611 users...\n",
      "Processing users 0 to 100...\n",
      "Processing users 100 to 200...\n",
      "Processing users 200 to 300...\n",
      "Processing users 300 to 400...\n",
      "Processing users 400 to 500...\n",
      "Processing users 500 to 600...\n",
      "Processing users 600 to 611...\n",
      "Completed recommendation computation in 544.01 seconds\n",
      "Saved computation metadata\n"
     ]
    }
   ],
   "source": [
    "computer = EnhancedRecommendationPreComputer(\n",
    "    items_df=items_df,\n",
    "    user_profiles_df=user_interactions_df,\n",
    "    user_embeddings=user_embeddings,\n",
    "    item_embeddings=item_embeddings,\n",
    "    user_feedback_df=None,  # Optional\n",
    "    user_demographic_df=None  # Optional\n",
    ")\n",
    "\n",
    "# Compute all recommendations\n",
    "computer.compute_all_recommendations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedRecommendationServer:\n",
    "    \"\"\"Serves recommendations with feedback handling and cold-start support\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 recommendations_path: str = 'recommendation_data/recommendations.csv',\n",
    "                 feedback_store: Optional[str] = None):\n",
    "        \"\"\"Initialize server with recommendations and feedback storage\"\"\"\n",
    "        print(\"Loading recommendations...\")\n",
    "        self.recommendations_df = pd.read_csv(recommendations_path)\n",
    "        \n",
    "        # Convert user_id to string to ensure consistent type handling\n",
    "        self.recommendations_df['user_id'] = self.recommendations_df['user_id'].astype(str)\n",
    "        \n",
    "        # Create indices for faster lookup\n",
    "        self.user_recs = self.recommendations_df.groupby('user_id')\n",
    "        \n",
    "        # Initialize feedback storage\n",
    "        self.feedback_store = feedback_store or 'recommendation_data/feedback.csv'\n",
    "        self._init_feedback_store()\n",
    "        \n",
    "        # Load cold start recommendations\n",
    "        self.cold_start_recs = self.recommendations_df[\n",
    "            self.recommendations_df['user_id'] == 'COLD_START'\n",
    "        ]\n",
    "        \n",
    "        print(f\"Loaded {len(self.recommendations_df)} recommendations for {len(self.user_recs.groups)} users\")\n",
    "    \n",
    "    def _init_feedback_store(self):\n",
    "        \"\"\"Initialize feedback storage\"\"\"\n",
    "        if not Path(self.feedback_store).exists():\n",
    "            pd.DataFrame(columns=[\n",
    "                'user_id', \n",
    "                'item_id', \n",
    "                'rating', \n",
    "                'user_movie_tags',  # Store as dictionary string\n",
    "                'timestamp', \n",
    "                'recommendation_type'\n",
    "            ]).to_csv(self.feedback_store, index=False)\n",
    "    \n",
    "    def get_recommendations(self, \n",
    "                          user_id: str,\n",
    "                          n_recommendations: int = 10,\n",
    "                          randomize: bool = True,\n",
    "                          user_data: Optional[Dict] = None) -> Dict:\n",
    "        \"\"\"Get recommendations with cold-start handling\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Ensure user_id is string\n",
    "        user_id = str(user_id)\n",
    "        \n",
    "        try:\n",
    "            # Check if user has existing recommendations\n",
    "            if user_id in self.user_recs.groups:\n",
    "                recommendations = self._get_personalized_recommendations(\n",
    "                    user_id, n_recommendations, randomize\n",
    "                )\n",
    "                rec_type = 'personalized'\n",
    "            else:\n",
    "                # Use cold start recommendations\n",
    "                recommendations = self._get_cold_start_recommendations(\n",
    "                    n_recommendations, user_data\n",
    "                )\n",
    "                rec_type = 'cold_start'\n",
    "            \n",
    "            return {\n",
    "                'recommendations': recommendations,\n",
    "                'metadata': {\n",
    "                    'serving_time': time.time() - start_time,\n",
    "                    'user_id': user_id,\n",
    "                    'recommendation_type': rec_type,\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                }\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error getting recommendations: {str(e)}\")\n",
    "            return {\n",
    "                'error': str(e),\n",
    "                'recommendations': [],\n",
    "                'metadata': {\n",
    "                    'serving_time': time.time() - start_time,\n",
    "                    'user_id': user_id,\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                }\n",
    "            }\n",
    "    \n",
    "    def _get_personalized_recommendations(self, \n",
    "                                        user_id: str,\n",
    "                                        n_recommendations: int,\n",
    "                                        randomize: bool) -> List[Dict]:\n",
    "        \"\"\"Get personalized recommendations for existing user\"\"\"\n",
    "        user_recs = self.user_recs.get_group(user_id).copy()\n",
    "        \n",
    "        if randomize:\n",
    "            noise = np.random.normal(0, 0.1, size=len(user_recs))\n",
    "            user_recs['randomized_score'] = user_recs['score'] + noise\n",
    "            user_recs = user_recs.nlargest(n_recommendations, 'randomized_score')\n",
    "        else:\n",
    "            user_recs = user_recs.nsmallest(n_recommendations, 'rank')\n",
    "        \n",
    "        # Convert to records and ensure numeric types are Python native\n",
    "        recommendations = user_recs.to_dict('records')\n",
    "        for rec in recommendations:\n",
    "            rec['score'] = float(rec['score'])\n",
    "            rec['rank'] = int(rec['rank'])\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def _get_cold_start_recommendations(self,\n",
    "                                      n_recommendations: int,\n",
    "                                      user_data: Optional[Dict] = None) -> List[Dict]:\n",
    "        \"\"\"Get cold start recommendations, optionally using user data\"\"\"\n",
    "        if user_data:\n",
    "            filtered_recs = self.cold_start_recs.copy()\n",
    "            \n",
    "            # Filter by preferred genres if available\n",
    "            if 'preferred_genres' in user_data:\n",
    "                filtered_recs = filtered_recs[\n",
    "                    filtered_recs['genres'].apply(\n",
    "                        lambda x: any(genre in x for genre in user_data['preferred_genres'])\n",
    "                    )\n",
    "                ]\n",
    "            \n",
    "            # Filter by preferred tags if available\n",
    "            if 'preferred_tags' in user_data and len(filtered_recs) >= n_recommendations:\n",
    "                # Add tag similarity score\n",
    "                filtered_recs['tag_score'] = filtered_recs['user_movie_tags'].apply(\n",
    "                    lambda x: len(set(x).intersection(user_data['preferred_tags']))\n",
    "                )\n",
    "                filtered_recs = filtered_recs.nlargest(n_recommendations, 'tag_score')\n",
    "            \n",
    "            if len(filtered_recs) >= n_recommendations:\n",
    "                return filtered_recs.head(n_recommendations).to_dict('records')\n",
    "        \n",
    "        # Fall back to general cold start recommendations\n",
    "        return self.cold_start_recs.head(n_recommendations).to_dict('records')\n",
    "    \n",
    "    def record_feedback(self,\n",
    "                       user_id: str,\n",
    "                       item_id: int,\n",
    "                       rating: float,\n",
    "                       recommendation_type: Optional[str] = 'personalized',\n",
    "                       user_movie_tags: Optional[str] = 'No tags'):\n",
    "        \"\"\"Record user feedback for future improvements\"\"\"\n",
    "        feedback = pd.DataFrame([{\n",
    "            'user_id': str(user_id),\n",
    "            'item_id': item_id,\n",
    "            'rating': rating,\n",
    "            'user_movie_tags': json.dumps(user_movie_tags) if user_movie_tags else '[]',\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'recommendation_type': recommendation_type\n",
    "        }])\n",
    "        \n",
    "        feedback.to_csv(self.feedback_store, mode='a', header=False, index=False)\n",
    "        print(f\"Recorded feedback for user {user_id} on item {item_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading recommendations...\n",
      "Loaded 61100 recommendations for 611 users\n"
     ]
    }
   ],
   "source": [
    "server = EnhancedRecommendationServer(\n",
    "    recommendations_path='recommendation_data/recommendations.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recommendations': [{'user_id': '1',\n",
       "   'item_id': 7643,\n",
       "   'title': 'Whiplash ',\n",
       "   'genres': '(no genres listed)',\n",
       "   'score': 19.450000000000003,\n",
       "   'rank': 22,\n",
       "   'recommendation_type': 'personalized',\n",
       "   'randomized_score': 19.598587265221152},\n",
       "  {'user_id': '1',\n",
       "   'item_id': 8626,\n",
       "   'title': 'A Cosmic Christmas ',\n",
       "   'genres': '(no genres listed)',\n",
       "   'score': 19.450000000000003,\n",
       "   'rank': 13,\n",
       "   'recommendation_type': 'personalized',\n",
       "   'randomized_score': 19.59104354703169},\n",
       "  {'user_id': '1',\n",
       "   'item_id': 9295,\n",
       "   'title': 'The Forbidden Dance ',\n",
       "   'genres': '(no genres listed)',\n",
       "   'score': 19.450000000000003,\n",
       "   'rank': 17,\n",
       "   'recommendation_type': 'personalized',\n",
       "   'randomized_score': 19.5834147516201},\n",
       "  {'user_id': '1',\n",
       "   'item_id': 2880,\n",
       "   'title': 'The Putin Interviews ',\n",
       "   'genres': '(no genres listed)',\n",
       "   'score': 19.450000000000003,\n",
       "   'rank': 14,\n",
       "   'recommendation_type': 'personalized',\n",
       "   'randomized_score': 19.5721397238283},\n",
       "  {'user_id': '1',\n",
       "   'item_id': 3124,\n",
       "   'title': 'The Godfather Trilogy: 1972-1990 ',\n",
       "   'genres': '(no genres listed)',\n",
       "   'score': 19.450000000000003,\n",
       "   'rank': 16,\n",
       "   'recommendation_type': 'personalized',\n",
       "   'randomized_score': 19.549823964021336},\n",
       "  {'user_id': '1',\n",
       "   'item_id': 8951,\n",
       "   'title': 'Guardians ',\n",
       "   'genres': '(no genres listed)',\n",
       "   'score': 19.450000000000003,\n",
       "   'rank': 10,\n",
       "   'recommendation_type': 'personalized',\n",
       "   'randomized_score': 19.54965892865065},\n",
       "  {'user_id': '1',\n",
       "   'item_id': 8773,\n",
       "   'title': 'Green Room ',\n",
       "   'genres': '(no genres listed)',\n",
       "   'score': 19.450000000000003,\n",
       "   'rank': 19,\n",
       "   'recommendation_type': 'personalized',\n",
       "   'randomized_score': 19.493314820624803},\n",
       "  {'user_id': '1',\n",
       "   'item_id': 9270,\n",
       "   'title': 'Let It Be Me ',\n",
       "   'genres': '(no genres listed)',\n",
       "   'score': 19.450000000000003,\n",
       "   'rank': 20,\n",
       "   'recommendation_type': 'personalized',\n",
       "   'randomized_score': 19.473597591406595},\n",
       "  {'user_id': '1',\n",
       "   'item_id': 8958,\n",
       "   'title': 'Serving in Silence: The Margarethe Cammermeyer Story ',\n",
       "   'genres': '(no genres listed)',\n",
       "   'score': 19.450000000000003,\n",
       "   'rank': 7,\n",
       "   'recommendation_type': 'personalized',\n",
       "   'randomized_score': 19.473423981461664},\n",
       "  {'user_id': '1',\n",
       "   'item_id': 6487,\n",
       "   'title': 'Lemonade ',\n",
       "   'genres': '(no genres listed)',\n",
       "   'score': 19.450000000000003,\n",
       "   'rank': 8,\n",
       "   'recommendation_type': 'personalized',\n",
       "   'randomized_score': 19.465117939401328}],\n",
       " 'metadata': {'serving_time': 0.006516933441162109,\n",
       "  'user_id': '1',\n",
       "  'recommendation_type': 'personalized',\n",
       "  'timestamp': '2025-01-20T11:34:32.502674'}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get recommendations for known user\n",
    "recs = server.get_recommendations(\n",
    "    user_id=\"1\",\n",
    "    n_recommendations=10\n",
    ")\n",
    "recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recommendations': [{'user_id': '55',\n",
       "   'item_id': 2840,\n",
       "   'title': 'La cravate ',\n",
       "   'genres': '(no genres listed)',\n",
       "   'score': 19.450000000000003,\n",
       "   'rank': 1,\n",
       "   'recommendation_type': 'personalized',\n",
       "   'randomized_score': 19.68799447414829},\n",
       "  {'user_id': '55',\n",
       "   'item_id': 8958,\n",
       "   'title': 'Serving in Silence: The Margarethe Cammermeyer Story ',\n",
       "   'genres': '(no genres listed)',\n",
       "   'score': 19.450000000000003,\n",
       "   'rank': 16,\n",
       "   'recommendation_type': 'personalized',\n",
       "   'randomized_score': 19.569623552793473},\n",
       "  {'user_id': '55',\n",
       "   'item_id': 4801,\n",
       "   'title': 'The Brand New Testament ',\n",
       "   'genres': '(no genres listed)',\n",
       "   'score': 19.450000000000003,\n",
       "   'rank': 23,\n",
       "   'recommendation_type': 'personalized',\n",
       "   'randomized_score': 19.56715178438762},\n",
       "  {'user_id': '55',\n",
       "   'item_id': 2008,\n",
       "   'title': 'Pirates of the Caribbean: Dead Men Tell No Tales ',\n",
       "   'genres': '(no genres listed)',\n",
       "   'score': 19.450000000000003,\n",
       "   'rank': 3,\n",
       "   'recommendation_type': 'personalized',\n",
       "   'randomized_score': 19.55244435282935},\n",
       "  {'user_id': '55',\n",
       "   'item_id': 8951,\n",
       "   'title': 'Guardians ',\n",
       "   'genres': '(no genres listed)',\n",
       "   'score': 19.450000000000003,\n",
       "   'rank': 22,\n",
       "   'recommendation_type': 'personalized',\n",
       "   'randomized_score': 19.55071281745535}],\n",
       " 'metadata': {'serving_time': 0.00400090217590332,\n",
       "  'user_id': '55',\n",
       "  'recommendation_type': 'personalized',\n",
       "  'timestamp': '2025-01-20T11:34:32.921394'}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get recommendations for new user\n",
    "new_user_recs = server.get_recommendations(\n",
    "    user_id=str(55),\n",
    "    n_recommendations=5,\n",
    "    user_data={\"preferred_genres\": [\"Action\", \"Drama\"]}\n",
    ")\n",
    "new_user_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorded feedback for user 9999 on item 5\n"
     ]
    }
   ],
   "source": [
    "server.record_feedback(\n",
    "    user_id=str(9999),\n",
    "    item_id=5,\n",
    "    rating=4,\n",
    "    user_movie_tags='Muito bom!'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "Rating metrics are similar to regression metrics used for evaluating a regression model that predicts numerical values given input observations. In the context of recommendation system, rating metrics are to evaluate how accurate a recommender is to predict ratings that users may give to items. Therefore, the metrics are calculated exactly on the same group of (user, item) pairs that exist in both ground-truth dataset and prediction dataset and averaged by the total number of users.\n",
    "\n",
    "Use cases\n",
    "Rating metrics are effective in measuring the model accuracy. However, in some cases, the rating metrics are limited if:\n",
    "* the recommender is to predict ranking instead of explicit rating. For example, if the consumer of the recommender cares about the ranked recommended items, rating metrics do not apply directly. Usually a relevancy function such as top-k will be applied to generate the ranked list from predicted ratings in order to evaluate the recommender with other metrics.\n",
    "* the recommender is to generate recommendation scores that have different scales with the original ratings (e.g., the SAR algorithm). In this case, the difference between the generated scores and the original scores (or, ratings) is not valid for measuring accuracy of the model.\n",
    "\n",
    "Seeing the current use case regards the prediction of a customer rating, rating metrics were chosen to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, precision_score, recall_score, f1_score\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import pandas as pd\n",
    "\n",
    "class RecommenderEvaluator:\n",
    "    \"\"\"Evaluates recommender system performance using various metrics\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 recommender_server,\n",
    "                 test_data: pd.DataFrame,\n",
    "                 k_values: List[int] = [5, 10, 20]):\n",
    "        \"\"\"\n",
    "        Initialize evaluator\n",
    "        \n",
    "        Args:\n",
    "            recommender_server: Instance of EnhancedRecommendationServer\n",
    "            test_data: DataFrame with ground truth data (user_id, item_id, rating)\n",
    "            k_values: List of k values for which to compute ranking metrics\n",
    "        \"\"\"\n",
    "        self.recommender = recommender_server\n",
    "        self.test_data = test_data\n",
    "        self.k_values = k_values\n",
    "        \n",
    "    def evaluate_all(self) -> Dict:\n",
    "        \"\"\"Run all evaluations and return results\"\"\"\n",
    "        print(\"Starting evaluation...\")\n",
    "        \n",
    "        # Rating prediction metrics\n",
    "        rmse, mae, variance, r2 = self.compute_rating_metrics()\n",
    "        \n",
    "        return {\n",
    "            'rating_metrics': {\n",
    "                'rmse': rmse,\n",
    "                'mae': mae,\n",
    "                'r2_score': r2,\n",
    "                'variance': variance\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def compute_rating_metrics(self) -> Tuple[float, float]:\n",
    "        \"\"\"Compute RMSE and MAE\"\"\"\n",
    "        print(\"Computing rating metrics...\")\n",
    "        \n",
    "        predictions = []\n",
    "        actuals = []\n",
    "        \n",
    "        for _, row in self.test_data.iterrows():\n",
    "            user_id = str(row['user_id'])\n",
    "            actual_rating = row['rating']\n",
    "            \n",
    "            # Get recommendations for user\n",
    "            recs = self.recommender.get_recommendations(\n",
    "                user_id=user_id,\n",
    "                n_recommendations=100,  # Get more to ensure we catch the rated item\n",
    "                randomize=False\n",
    "            )\n",
    "            \n",
    "            # Find the rating prediction for the specific item\n",
    "            for rec in recs['recommendations']:\n",
    "                if rec['item_id'] == row['item_id']:\n",
    "                    print(\"Item: \", rec['item_id'])\n",
    "                    print(\"Actual rating\", actual_rating)\n",
    "                    print(\"Predicted rating: \", rec['score'])\n",
    "                    predictions.append(rec['score'])\n",
    "                    actuals.append(actual_rating)\n",
    "                    break\n",
    "        \n",
    "        # Convert to numpy arrays\n",
    "        predictions = np.array(predictions)\n",
    "        actuals = np.array(actuals)\n",
    "        \n",
    "        # Compute metrics\n",
    "        rmse = np.sqrt(mean_squared_error(actuals, predictions))\n",
    "        mae = mean_absolute_error(actuals, predictions)\n",
    "\n",
    "        # Calculate the variance\n",
    "        variance = np.mean((actuals - predictions) ** 2)\n",
    "        \n",
    "        r2 = r2_score(actuals, predictions)\n",
    "\n",
    "        return rmse, mae, variance, r2\n",
    "    \n",
    "    def plot_metrics(self, results: Dict):\n",
    "        \"\"\"Plot evaluation metrics\"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        # Plot rating metrics\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        # Rating metrics\n",
    "        rating_metrics = results['rating_metrics']\n",
    "        plt.bar(['RMSE', 'MAE', 'R2', 'Variance'], [rating_metrics['rmse'], rating_metrics['mae'], rating_metrics['r2_score'], rating_metrics['variance']])\n",
    "        plt.title('Rating Prediction Metrics')\n",
    "        plt.ylabel('Error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users with >= 5 ratings: 610 out of 610\n",
      "\n",
      "Split Statistics:\n",
      "Total ratings: 100805\n",
      "Training ratings: 80872 (80.23%)\n",
      "Test ratings: 19933 (19.77%)\n",
      "Users in training: 610\n",
      "Users in test: 610\n",
      "Users in both: 610\n",
      "\n",
      "Minimum ratings per user in training: 16\n"
     ]
    }
   ],
   "source": [
    "def create_train_test_split(df: pd.DataFrame,\n",
    "                          test_size: float = 0.2,\n",
    "                          min_ratings: int = 5,\n",
    "                          min_train_ratings: int = 3,\n",
    "                          random_state: int = 42) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Create train-test split for recommender system evaluation\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with columns ['user_id', 'item_id', 'rating', ...]\n",
    "        test_size: Proportion of ratings to use for testing\n",
    "        min_ratings: Minimum total ratings required for a user to be included\n",
    "        min_train_ratings: Minimum ratings required in training set per user\n",
    "        random_state: Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "        train_df, test_df: Train and test DataFrames\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # 1. Filter users with minimum ratings\n",
    "    user_ratings_count = df.groupby('user_id').size()\n",
    "    valid_users = user_ratings_count[user_ratings_count >= min_ratings].index\n",
    "    filtered_df = df[df['user_id'].isin(valid_users)].copy()\n",
    "    \n",
    "    print(f\"Users with >= {min_ratings} ratings: {len(valid_users)} out of {df['user_id'].nunique()}\")\n",
    "    \n",
    "    # 2. Split data by user\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    \n",
    "    for user_id in valid_users:\n",
    "        user_ratings = filtered_df[filtered_df['user_id'] == user_id]\n",
    "        n_ratings = len(user_ratings)\n",
    "        \n",
    "        # Calculate number of test ratings ensuring min_train_ratings\n",
    "        n_test = min(\n",
    "            int(n_ratings * test_size),\n",
    "            n_ratings - min_train_ratings\n",
    "        )\n",
    "        \n",
    "        # Randomly select test ratings\n",
    "        test_indices = np.random.choice(\n",
    "            user_ratings.index,\n",
    "            size=n_test,\n",
    "            replace=False\n",
    "        )\n",
    "        \n",
    "        # Split the data\n",
    "        user_test = user_ratings.loc[test_indices]\n",
    "        user_train = user_ratings.drop(test_indices)\n",
    "        \n",
    "        train_data.append(user_train)\n",
    "        test_data.append(user_test)\n",
    "    \n",
    "    # 3. Combine splits\n",
    "    train_df = pd.concat(train_data, ignore_index=True)\n",
    "    test_df = pd.concat(test_data, ignore_index=True)\n",
    "    \n",
    "    # 4. Verify the split\n",
    "    train_users = train_df['user_id'].unique()\n",
    "    test_users = test_df['user_id'].unique()\n",
    "    \n",
    "    print(\"\\nSplit Statistics:\")\n",
    "    print(f\"Total ratings: {len(df)}\")\n",
    "    print(f\"Training ratings: {len(train_df)} ({len(train_df)/len(filtered_df):.2%})\")\n",
    "    print(f\"Test ratings: {len(test_df)} ({len(test_df)/len(filtered_df):.2%})\")\n",
    "    print(f\"Users in training: {len(train_users)}\")\n",
    "    print(f\"Users in test: {len(test_users)}\")\n",
    "    print(f\"Users in both: {len(set(train_users) & set(test_users))}\")\n",
    "    \n",
    "    # 5. Verify minimum ratings constraint\n",
    "    train_user_counts = train_df.groupby('user_id').size()\n",
    "    min_train_count = train_user_counts.min()\n",
    "    print(f\"\\nMinimum ratings per user in training: {min_train_count}\")\n",
    "    \n",
    "    return train_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading recommendations...\n",
      "Loaded 61100 recommendations for 611 users\n",
      "Starting evaluation...\n",
      "Computing rating metrics...\n",
      "Item:  2156\n",
      "Actual rating 5.0\n",
      "Predicted rating:  3.0125249500998\n",
      "Item:  625\n",
      "Actual rating 3.0\n",
      "Predicted rating:  2.954191616766467\n",
      "Item:  7264\n",
      "Actual rating 4.0\n",
      "Predicted rating:  5.755882352941176\n",
      "Item:  629\n",
      "Actual rating 2.5\n",
      "Predicted rating:  3.0125249500998\n",
      "Item:  3124\n",
      "Actual rating 2.0\n",
      "Predicted rating:  19.450000000000003\n",
      "Item:  2156\n",
      "Actual rating 4.5\n",
      "Predicted rating:  3.0125249500998\n",
      "Item:  6409\n",
      "Actual rating 4.0\n",
      "Predicted rating:  2.1967964279521413\n",
      "Item:  8446\n",
      "Actual rating 5.0\n",
      "Predicted rating:  2.3296509806568384\n",
      "Item:  607\n",
      "Actual rating 2.0\n",
      "Predicted rating:  2.1491234422819847\n",
      "Item:  1154\n",
      "Actual rating 3.0\n",
      "Predicted rating:  2.954191616766467\n",
      "Item:  830\n",
      "Actual rating 4.5\n",
      "Predicted rating:  2.2074567756153183\n",
      "Item:  607\n",
      "Actual rating 3.0\n",
      "Predicted rating:  2.1491234422819847\n",
      "Item:  5655\n",
      "Actual rating 3.0\n",
      "Predicted rating:  19.450000000000003\n",
      "Item:  3231\n",
      "Actual rating 3.0\n",
      "Predicted rating:  2.954191616766467\n",
      "Item:  8443\n",
      "Actual rating 2.5\n",
      "Predicted rating:  2.9587653017007907\n",
      "Item:  8446\n",
      "Actual rating 5.0\n",
      "Predicted rating:  2.3296509806568384\n",
      "Item:  6409\n",
      "Actual rating 4.5\n",
      "Predicted rating:  2.1967964279521413\n",
      "Item:  3124\n",
      "Actual rating 4.0\n",
      "Predicted rating:  19.450000000000003\n",
      "Item:  337\n",
      "Actual rating 4.0\n",
      "Predicted rating:  2.605960027582741\n",
      "Item:  830\n",
      "Actual rating 3.0\n",
      "Predicted rating:  2.2074567756153183\n",
      "Item:  1577\n",
      "Actual rating 4.0\n",
      "Predicted rating:  2.3198208992909284\n",
      "Item:  2844\n",
      "Actual rating 3.0\n",
      "Predicted rating:  2.954191616766467\n",
      "Item:  337\n",
      "Actual rating 3.5\n",
      "Predicted rating:  2.605960027582741\n",
      "Item:  3057\n",
      "Actual rating 4.0\n",
      "Predicted rating:  2.138463094618808\n",
      "Item:  2156\n",
      "Actual rating 5.0\n",
      "Predicted rating:  3.0125249500998\n",
      "Item:  3231\n",
      "Actual rating 5.0\n",
      "Predicted rating:  2.954191616766467\n",
      "Item:  9438\n",
      "Actual rating 4.0\n",
      "Predicted rating:  2.230324036611462\n",
      "Item:  8270\n",
      "Actual rating 3.0\n",
      "Predicted rating:  2.138463094618808\n",
      "Item:  3572\n",
      "Actual rating 4.0\n",
      "Predicted rating:  2.954191616766467\n",
      "Item:  2370\n",
      "Actual rating 4.0\n",
      "Predicted rating:  3.1875249500998004\n",
      "Item:  6409\n",
      "Actual rating 5.0\n",
      "Predicted rating:  2.1967964279521413\n",
      "Item:  2370\n",
      "Actual rating 4.5\n",
      "Predicted rating:  3.1875249500998004\n",
      "Item:  1107\n",
      "Actual rating 3.0\n",
      "Predicted rating:  2.1730793380817404\n",
      "Item:  347\n",
      "Actual rating 2.0\n",
      "Predicted rating:  2.124576086114318\n",
      "Item:  830\n",
      "Actual rating 3.0\n",
      "Predicted rating:  2.2074567756153183\n",
      "Item:  1107\n",
      "Actual rating 4.0\n",
      "Predicted rating:  2.1730793380817404\n",
      "Item:  2370\n",
      "Actual rating 4.0\n",
      "Predicted rating:  3.1875249500998004\n",
      "Item:  337\n",
      "Actual rating 3.0\n",
      "Predicted rating:  2.605960027582741\n",
      "Item:  7643\n",
      "Actual rating 4.0\n",
      "Predicted rating:  19.450000000000003\n",
      "Item:  8282\n",
      "Actual rating 0.5\n",
      "Predicted rating:  3.106040003941275\n",
      "Item:  8446\n",
      "Actual rating 5.0\n",
      "Predicted rating:  2.3296509806568384\n",
      "Item:  3007\n",
      "Actual rating 4.5\n",
      "Predicted rating:  2.3695007821504945\n",
      "Item:  830\n",
      "Actual rating 3.0\n",
      "Predicted rating:  2.2074567756153183\n",
      "Item:  337\n",
      "Actual rating 3.5\n",
      "Predicted rating:  2.516216437839152\n",
      "Item:  2370\n",
      "Actual rating 4.0\n",
      "Predicted rating:  3.27726853984339\n",
      "Item:  8446\n",
      "Actual rating 5.0\n",
      "Predicted rating:  2.3296509806568384\n",
      "Item:  551\n",
      "Actual rating 3.0\n",
      "Predicted rating:  3.129191616766467\n",
      "Item:  1162\n",
      "Actual rating 4.5\n",
      "Predicted rating:  2.378154232624261\n",
      "Item:  8357\n",
      "Actual rating 1.5\n",
      "Predicted rating:  3.0315201796519244\n",
      "Item:  5655\n",
      "Actual rating 4.5\n",
      "Predicted rating:  19.450000000000003\n",
      "Item:  5776\n",
      "Actual rating 4.0\n",
      "Predicted rating:  2.1829094194476517\n",
      "Item:  830\n",
      "Actual rating 4.0\n",
      "Predicted rating:  2.2074567756153183\n",
      "Item:  2008\n",
      "Actual rating 1.5\n",
      "Predicted rating:  19.450000000000003\n",
      "Item:  337\n",
      "Actual rating 4.0\n",
      "Predicted rating:  2.605960027582741\n",
      "Item:  7697\n",
      "Actual rating 4.0\n",
      "Predicted rating:  2.138463094618808\n",
      "Item:  629\n",
      "Actual rating 3.0\n",
      "Predicted rating:  3.0125249500998\n",
      "Item:  551\n",
      "Actual rating 3.0\n",
      "Predicted rating:  3.0708582834331337\n",
      "Item:  3007\n",
      "Actual rating 4.0\n",
      "Predicted rating:  2.3695007821504945\n",
      "Item:  607\n",
      "Actual rating 1.5\n",
      "Predicted rating:  2.1491234422819847\n",
      "Item:  607\n",
      "Actual rating 3.5\n",
      "Predicted rating:  2.154426472585015\n",
      "Item:  2370\n",
      "Actual rating 5.0\n",
      "Predicted rating:  3.1875249500998004\n",
      "Item:  3227\n",
      "Actual rating 2.5\n",
      "Predicted rating:  3.0125249500998\n",
      "Item:  6409\n",
      "Actual rating 4.0\n",
      "Predicted rating:  2.1967964279521413\n",
      "Item:  337\n",
      "Actual rating 4.0\n",
      "Predicted rating:  2.605960027582741\n",
      "Item:  830\n",
      "Actual rating 1.0\n",
      "Predicted rating:  2.2074567756153183\n",
      "Item:  5776\n",
      "Actual rating 5.0\n",
      "Predicted rating:  2.1829094194476517\n",
      "Item:  8282\n",
      "Actual rating 4.0\n",
      "Predicted rating:  3.106040003941275\n",
      "Item:  2370\n",
      "Actual rating 4.0\n",
      "Predicted rating:  3.1875249500998004\n",
      "Item:  337\n",
      "Actual rating 4.0\n",
      "Predicted rating:  2.605960027582741\n",
      "Item:  551\n",
      "Actual rating 5.0\n",
      "Predicted rating:  3.0708582834331337\n",
      "Item:  6441\n",
      "Actual rating 3.5\n",
      "Predicted rating:  5.755882352941176\n",
      "Item:  2370\n",
      "Actual rating 3.5\n",
      "Predicted rating:  3.245858283433133\n",
      "Item:  2237\n",
      "Actual rating 2.5\n",
      "Predicted rating:  2.954191616766467\n",
      "Item:  7643\n",
      "Actual rating 4.5\n",
      "Predicted rating:  19.450000000000003\n",
      "Item:  2370\n",
      "Actual rating 3.0\n",
      "Predicted rating:  3.1875249500998004\n",
      "Item:  4956\n",
      "Actual rating 4.0\n",
      "Predicted rating:  2.954191616766467\n",
      "Item:  8446\n",
      "Actual rating 4.0\n",
      "Predicted rating:  2.3296509806568384\n",
      "Item:  7697\n",
      "Actual rating 3.0\n",
      "Predicted rating:  2.288463094618808\n",
      "Item:  5776\n",
      "Actual rating 4.5\n",
      "Predicted rating:  2.2245760861143182\n",
      "Item:  8443\n",
      "Actual rating 3.5\n",
      "Predicted rating:  2.9587653017007907\n",
      "Item:  4586\n",
      "Actual rating 1.5\n",
      "Predicted rating:  19.450000000000003\n",
      "Item:  6409\n",
      "Actual rating 4.0\n",
      "Predicted rating:  2.1967964279521413\n",
      "Item:  1577\n",
      "Actual rating 4.0\n",
      "Predicted rating:  2.3198208992909284\n",
      "Item:  337\n",
      "Actual rating 3.0\n",
      "Predicted rating:  2.605960027582741\n",
      "Item:  5776\n",
      "Actual rating 3.5\n",
      "Predicted rating:  2.1829094194476517\n",
      "Item:  337\n",
      "Actual rating 3.0\n",
      "Predicted rating:  2.605960027582741\n",
      "Item:  7949\n",
      "Actual rating 4.0\n",
      "Predicted rating:  19.450000000000003\n",
      "Item:  6409\n",
      "Actual rating 4.5\n",
      "Predicted rating:  2.1967964279521413\n",
      "Item:  8193\n",
      "Actual rating 3.0\n",
      "Predicted rating:  3.106040003941275\n",
      "Item:  8446\n",
      "Actual rating 3.0\n",
      "Predicted rating:  2.3296509806568384\n",
      "Item:  337\n",
      "Actual rating 4.0\n",
      "Predicted rating:  2.605960027582741\n",
      "Item:  337\n",
      "Actual rating 5.0\n",
      "Predicted rating:  2.605960027582741\n",
      "Item:  551\n",
      "Actual rating 3.0\n",
      "Predicted rating:  3.0708582834331337\n",
      "Item:  8658\n",
      "Actual rating 3.0\n",
      "Predicted rating:  19.450000000000003\n",
      "Item:  4956\n",
      "Actual rating 4.0\n",
      "Predicted rating:  2.954191616766467\n",
      "Item:  3057\n",
      "Actual rating 5.0\n",
      "Predicted rating:  2.138463094618808\n",
      "Item:  5471\n",
      "Actual rating 4.0\n",
      "Predicted rating:  19.450000000000003\n",
      "Item:  6409\n",
      "Actual rating 3.0\n",
      "Predicted rating:  2.1967964279521413\n",
      "Item:  2094\n",
      "Actual rating 3.5\n",
      "Predicted rating:  3.106040003941275\n",
      "Item:  830\n",
      "Actual rating 3.0\n",
      "Predicted rating:  2.2074567756153183\n",
      "Item:  337\n",
      "Actual rating 3.0\n",
      "Predicted rating:  2.605960027582741\n",
      "Item:  551\n",
      "Actual rating 2.0\n",
      "Predicted rating:  3.0708582834331337\n",
      "Item:  607\n",
      "Actual rating 2.0\n",
      "Predicted rating:  2.1491234422819847\n",
      "Item:  2370\n",
      "Actual rating 4.0\n",
      "Predicted rating:  3.1875249500998004\n",
      "Item:  551\n",
      "Actual rating 4.0\n",
      "Predicted rating:  3.0708582834331337\n",
      "Item:  3057\n",
      "Actual rating 3.0\n",
      "Predicted rating:  2.138463094618808\n",
      "Item:  830\n",
      "Actual rating 4.0\n",
      "Predicted rating:  2.2074567756153183\n",
      "Item:  2370\n",
      "Actual rating 4.5\n",
      "Predicted rating:  3.245858283433133\n",
      "Item:  6409\n",
      "Actual rating 3.0\n",
      "Predicted rating:  2.188463048124825\n",
      "Item:  337\n",
      "Actual rating 2.5\n",
      "Predicted rating:  2.605960027582741\n",
      "Item:  551\n",
      "Actual rating 3.0\n",
      "Predicted rating:  3.0708582834331337\n",
      "Item:  2370\n",
      "Actual rating 4.0\n",
      "Predicted rating:  3.1875249500998004\n",
      "Item:  337\n",
      "Actual rating 2.5\n",
      "Predicted rating:  2.605960027582741\n",
      "Item:  2370\n",
      "Actual rating 4.5\n",
      "Predicted rating:  3.1875249500998004\n",
      "Item:  337\n",
      "Actual rating 4.0\n",
      "Predicted rating:  2.605960027582741\n",
      "Item:  8443\n",
      "Actual rating 1.5\n",
      "Predicted rating:  2.9587653017007907\n",
      "Item:  8288\n",
      "Actual rating 4.0\n",
      "Predicted rating:  2.124576086114318\n",
      "Item:  8193\n",
      "Actual rating 2.5\n",
      "Predicted rating:  3.106040003941275\n",
      "Item:  830\n",
      "Actual rating 4.0\n",
      "Predicted rating:  2.2074567756153183\n",
      "Item:  337\n",
      "Actual rating 3.0\n",
      "Predicted rating:  2.605960027582741\n",
      "Item:  337\n",
      "Actual rating 3.0\n",
      "Predicted rating:  2.605960027582741\n",
      "Item:  8446\n",
      "Actual rating 3.5\n",
      "Predicted rating:  2.3296509806568384\n",
      "Item:  337\n",
      "Actual rating 4.0\n",
      "Predicted rating:  2.605960027582741\n",
      "Item:  1154\n",
      "Actual rating 3.0\n",
      "Predicted rating:  2.954191616766467\n",
      "Item:  2156\n",
      "Actual rating 5.0\n",
      "Predicted rating:  3.0125249500998\n",
      "Item:  337\n",
      "Actual rating 5.0\n",
      "Predicted rating:  2.605960027582741\n",
      "Item:  5776\n",
      "Actual rating 4.0\n",
      "Predicted rating:  2.311242972661311\n",
      "Item:  4741\n",
      "Actual rating 3.5\n",
      "Predicted rating:  2.138463094618808\n",
      "Item:  8446\n",
      "Actual rating 4.5\n",
      "Predicted rating:  2.3296509806568384\n",
      "Item:  5776\n",
      "Actual rating 5.0\n",
      "Predicted rating:  2.178422295426284\n",
      "Item:  5655\n",
      "Actual rating 4.5\n",
      "Predicted rating:  19.450000000000003\n",
      "Item:  830\n",
      "Actual rating 3.0\n",
      "Predicted rating:  2.2074567756153183\n",
      "Item:  2370\n",
      "Actual rating 4.5\n",
      "Predicted rating:  3.1875249500998004\n",
      "Item:  7464\n",
      "Actual rating 3.5\n",
      "Predicted rating:  2.138463094618808\n",
      "Item:  337\n",
      "Actual rating 4.0\n",
      "Predicted rating:  2.605960027582741\n",
      "Item:  337\n",
      "Actual rating 5.0\n",
      "Predicted rating:  2.605960027582741\n",
      "Item:  337\n",
      "Actual rating 3.0\n",
      "Predicted rating:  2.605960027582741\n",
      "Item:  2945\n",
      "Actual rating 1.5\n",
      "Predicted rating:  2.3198208992909284\n",
      "Item:  607\n",
      "Actual rating 0.5\n",
      "Predicted rating:  2.1491234422819847\n",
      "Item:  5776\n",
      "Actual rating 4.0\n",
      "Predicted rating:  2.124576086114318\n",
      "Item:  6441\n",
      "Actual rating 5.0\n",
      "Predicted rating:  5.755882352941176\n",
      "Item:  4761\n",
      "Actual rating 4.0\n",
      "Predicted rating:  2.124576086114318\n",
      "Item:  607\n",
      "Actual rating 3.0\n",
      "Predicted rating:  2.1491234422819847\n",
      "Item:  8446\n",
      "Actual rating 3.0\n",
      "Predicted rating:  2.3296509806568384\n",
      "Item:  2370\n",
      "Actual rating 4.0\n",
      "Predicted rating:  3.1875249500998004\n",
      "Item:  1162\n",
      "Actual rating 4.0\n",
      "Predicted rating:  2.378154232624261\n",
      "Item:  2370\n",
      "Actual rating 5.0\n",
      "Predicted rating:  3.1875249500998004\n",
      "Item:  7181\n",
      "Actual rating 1.5\n",
      "Predicted rating:  19.450000000000003\n",
      "Item:  8446\n",
      "Actual rating 3.5\n",
      "Predicted rating:  2.325163801169659\n",
      "Item:  337\n",
      "Actual rating 3.0\n",
      "Predicted rating:  2.605960027582741\n",
      "Item:  2370\n",
      "Actual rating 4.0\n",
      "Predicted rating:  3.1875249500998004\n",
      "Item:  2094\n",
      "Actual rating 3.0\n",
      "Predicted rating:  3.106040003941275\n",
      "Item:  1107\n",
      "Actual rating 3.0\n",
      "Predicted rating:  2.1730793380817404\n",
      "Item:  8446\n",
      "Actual rating 5.0\n",
      "Predicted rating:  2.3296509806568384\n",
      "Item:  337\n",
      "Actual rating 3.0\n",
      "Predicted rating:  2.605960027582741\n",
      "Item:  4956\n",
      "Actual rating 3.0\n",
      "Predicted rating:  2.954191616766467\n",
      "Item:  830\n",
      "Actual rating 2.5\n",
      "Predicted rating:  2.2074567756153183\n",
      "Item:  607\n",
      "Actual rating 2.0\n",
      "Predicted rating:  2.1491234422819847\n",
      "Item:  8193\n",
      "Actual rating 2.5\n",
      "Predicted rating:  3.106040003941275\n",
      "Item:  8446\n",
      "Actual rating 3.5\n",
      "Predicted rating:  2.3296509806568384\n",
      "Item:  9348\n",
      "Actual rating 4.0\n",
      "Predicted rating:  2.124576086114318\n",
      "Item:  2156\n",
      "Actual rating 4.0\n",
      "Predicted rating:  3.0125249500998\n",
      "Item:  607\n",
      "Actual rating 2.5\n",
      "Predicted rating:  2.1491234422819847\n",
      "Item:  2370\n",
      "Actual rating 3.0\n",
      "Predicted rating:  3.245858283433133\n",
      "Item:  1107\n",
      "Actual rating 2.5\n",
      "Predicted rating:  2.1730793380817404\n",
      "Item:  2156\n",
      "Actual rating 3.5\n",
      "Predicted rating:  3.0708582834331337\n",
      "Item:  3057\n",
      "Actual rating 3.0\n",
      "Predicted rating:  2.138463094618808\n",
      "Item:  9436\n",
      "Actual rating 3.0\n",
      "Predicted rating:  2.230324036611462\n",
      "Item:  8282\n",
      "Actual rating 3.5\n",
      "Predicted rating:  3.106040003941275\n",
      "Item:  8958\n",
      "Actual rating 2.5\n",
      "Predicted rating:  19.450000000000003\n",
      "Item:  337\n",
      "Actual rating 3.0\n",
      "Predicted rating:  2.605960027582741\n",
      "Item:  6441\n",
      "Actual rating 4.0\n",
      "Predicted rating:  5.755882352941176\n",
      "Item:  6393\n",
      "Actual rating 3.0\n",
      "Predicted rating:  2.954191616766467\n",
      "Item:  407\n",
      "Actual rating 4.0\n",
      "Predicted rating:  2.954191616766467\n",
      "Item:  1162\n",
      "Actual rating 4.5\n",
      "Predicted rating:  2.3198208992909284\n",
      "Item:  337\n",
      "Actual rating 4.0\n",
      "Predicted rating:  2.605960027582741\n",
      "Item:  1577\n",
      "Actual rating 4.5\n",
      "Predicted rating:  2.3198208992909284\n",
      "Item:  551\n",
      "Actual rating 3.0\n",
      "Predicted rating:  3.0708582834331337\n",
      "Item:  337\n",
      "Actual rating 3.0\n",
      "Predicted rating:  2.605960027582741\n",
      "Item:  8282\n",
      "Actual rating 4.0\n",
      "Predicted rating:  3.156040003941275\n",
      "Item:  6683\n",
      "Actual rating 2.0\n",
      "Predicted rating:  3.0087653017007905\n",
      "Item:  9295\n",
      "Actual rating 4.5\n",
      "Predicted rating:  19.450000000000003\n",
      "Item:  8839\n",
      "Actual rating 4.0\n",
      "Predicted rating:  19.450000000000003\n",
      "Item:  8446\n",
      "Actual rating 4.5\n",
      "Predicted rating:  2.3713176473235054\n",
      "{'rating_metrics': {'rmse': 4.952558406011317, 'mae': 2.4611008568219095, 'r2_score': -25.70164145378213, 'variance': 24.527834764953358}}\n"
     ]
    }
   ],
   "source": [
    "# Initialize recommender server\n",
    "recommender = EnhancedRecommendationServer(\n",
    "    recommendations_path='recommendation_data/recommendations.csv'\n",
    ")\n",
    "\n",
    "# Random split\n",
    "train_df, test_df = create_train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    min_ratings=5,\n",
    "    min_train_ratings=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Initialize evaluator\n",
    "evaluator = RecommenderEvaluator(\n",
    "    recommender_server=recommender,\n",
    "    test_data=test_df,\n",
    "    k_values=[5, 10, 100]\n",
    ")\n",
    "\n",
    "# Run evaluation\n",
    "results = evaluator.evaluate_all()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rating Prediction Metrics:\n",
      "RMSE: 4.9526\n",
      "MAE: 2.4611\n",
      "R2: -25.7016\n",
      "Variance: 24.5278\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print results\n",
    "print(\"\\nRating Prediction Metrics:\")\n",
    "print(f\"RMSE: {results['rating_metrics']['rmse']:.4f}\")\n",
    "print(f\"MAE: {results['rating_metrics']['mae']:.4f}\")\n",
    "print(f\"R2: {results['rating_metrics']['r2_score']:.4f}\")\n",
    "print(f\"Variance: {results['rating_metrics']['variance']:.4f}\")\n",
    "\n",
    "# Plot metrics\n",
    "evaluator.plot_metrics(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Will watch for changes in these directories: ['c:\\\\Users\\\\Pedro Alves\\\\Documents\\\\DS_Projects\\\\recommender_system_embeddings']\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8003 (Press CTRL+C to quit)\n",
      "INFO:     Started reloader process [26936] using StatReload\n",
      "INFO:     Stopping reloader process [26936]\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, Dict\n",
    "import uvicorn\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Pydantic models for request/response validation\n",
    "class UserData(BaseModel):\n",
    "    preferred_genres: Optional[List[str]] = Field(default=None, description=\"List of preferred genres\")\n",
    "    preferred_tags: Optional[List[str]] = Field(default=None, description=\"List of preferred tags\")\n",
    "\n",
    "class FeedbackData(BaseModel):\n",
    "    user_id: str = Field(..., min_length=1, max_length=6, pattern=r\"^(0|[1-9][0-9]*)$\", description=\"User ID\")\n",
    "    item_id: int = Field(..., pattern=r\"^(0|[1-9][0-9]*)$\", description=\"Item ID\")\n",
    "    rating: float = Field(..., ge=0, le=5, description=\"Rating value between 0 and 5\")\n",
    "    user_movie_tags: Optional[str] = Field(default=None, min_length=1, max_length=50, description=\"User tags for the movie\")\n",
    "    recommendation_type: Optional[str] = Field(default=\"personalized\", description=\"Type of recommendation\")\n",
    "\n",
    "class Recommendation(BaseModel):\n",
    "    item_id: int\n",
    "    title: str\n",
    "    genres: str\n",
    "    score: float\n",
    "    rank: int\n",
    "\n",
    "class RecommendationResponse(BaseModel):\n",
    "    recommendations: List[Recommendation]\n",
    "    metadata: Dict\n",
    "\n",
    "app = FastAPI(\n",
    "    title=\"Movie Recommender API\",\n",
    "    description=\"API for serving personalized movie recommendations\",\n",
    "    version=\"1.0.0\"\n",
    ")\n",
    "\n",
    "# Global recommender instance\n",
    "recommender = None\n",
    "\n",
    "@app.on_event(\"startup\")\n",
    "async def startup_event():\n",
    "    \"\"\"Initialize recommender system on startup\"\"\"\n",
    "    global recommender\n",
    "    recommender = EnhancedRecommendationServer(\n",
    "        recommendations_path='recommendation_data/recommendations.csv'\n",
    "    )\n",
    "    print(\"Recommender system initialized\")\n",
    "\n",
    "@app.get(\"/health\")\n",
    "async def health_check():\n",
    "    \"\"\"Check if the API is running\"\"\"\n",
    "    return {\"status\": \"healthy\", \"timestamp\": datetime.now().isoformat()}\n",
    "\n",
    "@app.get(\"/recommendations/{user_id}\", response_model=RecommendationResponse)\n",
    "async def get_recommendations(\n",
    "    user_id: str,\n",
    "    n_recommendations: int = 10,\n",
    "    randomize: bool = True,\n",
    "    user_data: Optional[UserData] = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Get recommendations for a user\n",
    "    \n",
    "    Args:\n",
    "        user_id: User identifier\n",
    "        n_recommendations: Number of recommendations to return\n",
    "        randomize: Whether to add random noise to scores\n",
    "        user_data: Optional user preferences\n",
    "    \"\"\"\n",
    "    try:\n",
    "        recommendations = recommender.get_recommendations(\n",
    "            user_id=user_id,\n",
    "            n_recommendations=n_recommendations,\n",
    "            randomize=randomize,\n",
    "            user_data=user_data.dict() if user_data else None\n",
    "        )\n",
    "        return recommendations\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "@app.post(\"/feedback\")\n",
    "async def record_feedback(feedback: FeedbackData):\n",
    "    \"\"\"\n",
    "    Record user feedback for a recommendation\n",
    "    \n",
    "    Args:\n",
    "        feedback: Feedback data including user_id, item_id, rating, and optional tags\n",
    "    \"\"\"\n",
    "    try:\n",
    "        recommender.record_feedback(\n",
    "            user_id=feedback.user_id,\n",
    "            item_id=feedback.item_id,\n",
    "            rating=feedback.rating,\n",
    "            recommendation_type=feedback.recommendation_type,\n",
    "            user_movie_tags=feedback.user_movie_tags\n",
    "        )\n",
    "        return {\"status\": \"success\", \"message\": \"Feedback recorded successfully\"}\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "@app.get(\"/stats\")\n",
    "async def get_stats():\n",
    "    \"\"\"Get basic statistics about the recommender system\"\"\"\n",
    "    return {\n",
    "        \"total_recommendations\": len(recommender.recommendations_df),\n",
    "        \"total_users\": len(recommender.user_recs.groups),\n",
    "        \"cold_start_recommendations\": len(recommender.cold_start_recs),\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(\"main:app\", host=\"0.0.0.0\", port=8003, reload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
