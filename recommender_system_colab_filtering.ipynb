{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from typing import List, Tuple, Dict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df_ratings = pd.read_csv(\".\\\\ml-latest-small\\\\ratings.csv\").drop(columns=[\"timestamp\"])\n",
    "print(df_ratings.shape)\n",
    "print(df_ratings.info())\n",
    "df_ratings.columns = ['user_id', 'item_id', 'rating']\n",
    "df_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleRecommender:\n",
    "    def __init__(self, k_neighbors=5):\n",
    "        # Dictionary to store user ratings: {user_id: {item_id: rating}}\n",
    "        self.user_ratings = defaultdict(dict)\n",
    "        # Dictionary to store item ratings: {item_id: {user_id: rating}}\n",
    "        self.item_ratings = defaultdict(dict)\n",
    "        # Store mean ratings for normalization\n",
    "        self.user_means = {}\n",
    "        self.item_means = {}\n",
    "        self.k_neighbors = k_neighbors\n",
    "        \n",
    "    def fit(self, ratings_df):\n",
    "        \"\"\"\n",
    "        Process ratings data into user-item and item-user mappings\n",
    "        \n",
    "        Parameters:\n",
    "        ratings_df: DataFrame with columns [user_id, item_id, rating]\n",
    "        \"\"\"\n",
    "        # Create user-item and item-user matrices\n",
    "        for _, row in ratings_df.iterrows():\n",
    "            self.user_ratings[row['user_id']][row['item_id']] = row['rating']\n",
    "            self.item_ratings[row['item_id']][row['user_id']] = row['rating']\n",
    "            \n",
    "        # Calculate mean ratings for each user and item\n",
    "        for user_id, ratings in self.user_ratings.items():\n",
    "            self.user_means[user_id] = np.mean(list(ratings.values()))\n",
    "        \n",
    "        for item_id, ratings in self.item_ratings.items():\n",
    "            self.item_means[item_id] = np.mean(list(ratings.values()))\n",
    "    \n",
    "    def get_user_item_matrix(self):\n",
    "        \"\"\"Return the user-item matrix as a pandas DataFrame\"\"\"\n",
    "        data = []\n",
    "        for user_id in self.user_ratings:\n",
    "            for item_id in self.item_ratings:\n",
    "                rating = self.user_ratings[user_id].get(item_id, np.nan)\n",
    "                data.append([user_id, item_id, rating])\n",
    "        \n",
    "        return pd.DataFrame(data, columns=['user_id', 'item_id', 'rating']).pivot(\n",
    "            index='user_id', columns='item_id', values='rating'\n",
    "        )\n",
    "    \n",
    "    def compute_similarity(self, ratings1, ratings2, mean1, mean2):\n",
    "        \"\"\"\n",
    "        Compute adjusted cosine similarity between two rating vectors\n",
    "        \n",
    "        Parameters:\n",
    "        ratings1, ratings2: dictionaries of ratings\n",
    "        mean1, mean2: mean ratings for normalization\n",
    "        \"\"\"\n",
    "        common_ids = set(ratings1.keys()) & set(ratings2.keys())\n",
    "        \n",
    "        if len(common_ids) < 2:  # Require at least 2 common ratings\n",
    "            return 0.0\n",
    "        \n",
    "        # Calculate normalized ratings\n",
    "        norm1 = np.array([ratings1[i] - mean1 for i in common_ids])\n",
    "        norm2 = np.array([ratings2[i] - mean2 for i in common_ids])\n",
    "        \n",
    "        # Compute similarity using adjusted cosine similarity\n",
    "        num = np.dot(norm1, norm2)\n",
    "        den = np.sqrt(np.dot(norm1, norm1)) * np.sqrt(np.dot(norm2, norm2))\n",
    "        \n",
    "        return num / den if den != 0 else 0.0\n",
    "    \n",
    "    def get_top_n_items(self, user_id, n=10, method='item_based'):\n",
    "        \"\"\"\n",
    "        Get top N recommended items for a user\n",
    "        \n",
    "        Parameters:\n",
    "        user_id: ID of the user\n",
    "        n: Number of recommendations to return\n",
    "        method: 'item_based' or 'user_based'\n",
    "        \n",
    "        Returns:\n",
    "        List of tuples (item_id, predicted_rating)\n",
    "        \"\"\"\n",
    "        # Get items the user hasn't rated yet\n",
    "        rated_items = set(self.user_ratings[user_id].keys())\n",
    "        all_items = set(self.item_ratings.keys())\n",
    "        items_to_predict = all_items - rated_items\n",
    "        \n",
    "        # Predict ratings for all unrated items\n",
    "        predictions = []\n",
    "        for item_id in items_to_predict:\n",
    "            if method == 'item_based':\n",
    "                pred = self.predict_item_based(user_id, item_id)\n",
    "            else:\n",
    "                pred = self.predict_user_based(user_id, item_id)\n",
    "            predictions.append((item_id, pred))\n",
    "        \n",
    "        # Return top N items\n",
    "        return sorted(predictions, key=lambda x: x[1], reverse=True)[:n]\n",
    "    \n",
    "    def get_similar_items(self, item_id, n=10):\n",
    "        \"\"\"\n",
    "        Get N most similar items to a given item\n",
    "        \n",
    "        Parameters:\n",
    "        item_id: ID of the item\n",
    "        n: Number of similar items to return\n",
    "        \n",
    "        Returns:\n",
    "        List of tuples (item_id, similarity_score)\n",
    "        \"\"\"\n",
    "        if item_id not in self.item_ratings:\n",
    "            return []\n",
    "        \n",
    "        similarities = []\n",
    "        for other_item_id in self.item_ratings:\n",
    "            if other_item_id != item_id:\n",
    "                sim = self.compute_similarity(\n",
    "                    self.item_ratings[item_id],\n",
    "                    self.item_ratings[other_item_id],\n",
    "                    self.item_means[item_id],\n",
    "                    self.item_means[other_item_id]\n",
    "                )\n",
    "                similarities.append((other_item_id, sim))\n",
    "        \n",
    "        return sorted(similarities, key=lambda x: x[1], reverse=True)[:n]\n",
    "\n",
    "    def get_similar_users(self, user_id, n=10):\n",
    "        \"\"\"\n",
    "        Get N most similar users to a given user\n",
    "        \n",
    "        Parameters:\n",
    "        user_id: ID of the user\n",
    "        n: Number of similar users to return\n",
    "        \n",
    "        Returns:\n",
    "        List of tuples (user_id, similarity_score)\n",
    "        \"\"\"\n",
    "        if user_id not in self.user_ratings:\n",
    "            return []\n",
    "                \n",
    "        similarities = []\n",
    "        for other_user_id in self.user_ratings:\n",
    "            if other_user_id != user_id:\n",
    "                sim = self.compute_similarity(\n",
    "                    self.user_ratings[user_id],\n",
    "                    self.user_ratings[other_user_id],\n",
    "                    self.user_means[user_id],\n",
    "                    self.user_means[other_user_id]\n",
    "                )\n",
    "                similarities.append((other_user_id, sim))\n",
    "        \n",
    "        return sorted(similarities, key=lambda x: x[1], reverse=True)[:n]\n",
    "    \n",
    "    def predict_item_based(self, user_id, item_id):\n",
    "        \"\"\"Predict rating using item-based collaborative filtering\"\"\"\n",
    "        if item_id not in self.item_ratings:\n",
    "            return self.user_means.get(user_id, 0)\n",
    "        \n",
    "        # Find items rated by the user\n",
    "        user_items = self.user_ratings.get(user_id, {})\n",
    "        if not user_items:\n",
    "            return self.item_means.get(item_id, 0)\n",
    "        \n",
    "        # Compute similarities with items the user has rated\n",
    "        similarities = []\n",
    "        for rated_item_id in user_items:\n",
    "            if rated_item_id != item_id:\n",
    "                sim = self.compute_similarity(\n",
    "                    self.item_ratings[item_id],\n",
    "                    self.item_ratings[rated_item_id],\n",
    "                    self.item_means[item_id],\n",
    "                    self.item_means[rated_item_id]\n",
    "                )\n",
    "                similarities.append((sim, rated_item_id))\n",
    "        \n",
    "        # Get top k neighbors\n",
    "        neighbors = sorted(similarities, reverse=True)[:self.k_neighbors]\n",
    "        \n",
    "        if not neighbors:\n",
    "            return self.item_means.get(item_id, 0)\n",
    "        \n",
    "        # Weighted average of ratings\n",
    "        num = sum(sim * self.user_ratings[user_id][item_id] \n",
    "                 for sim, item_id in neighbors)\n",
    "        den = sum(abs(sim) for sim, _ in neighbors)\n",
    "        \n",
    "        return num / den if den != 0 else self.item_means.get(item_id, 0)\n",
    "    \n",
    "    def predict_user_based(self, user_id, item_id):\n",
    "        \"\"\"\n",
    "        Predict rating using user-based collaborative filtering\n",
    "        \n",
    "        Parameters:\n",
    "        user_id: ID of the user\n",
    "        item_id: ID of the item\n",
    "        \n",
    "        Returns:\n",
    "        Predicted rating\n",
    "        \"\"\"\n",
    "        if user_id not in self.user_ratings:\n",
    "            return self.item_means.get(item_id, 0)\n",
    "        \n",
    "        # Find users who rated the item\n",
    "        item_users = self.item_ratings.get(item_id, {})\n",
    "        if not item_users:\n",
    "            return self.user_means.get(user_id, 0)\n",
    "        \n",
    "        # Compute similarities with other users who rated this item\n",
    "        similarities = []\n",
    "        for other_user_id in item_users:\n",
    "            if other_user_id != user_id:\n",
    "                sim = self.compute_similarity(\n",
    "                    self.user_ratings[user_id],\n",
    "                    self.user_ratings[other_user_id],\n",
    "                    self.user_means[user_id],\n",
    "                    self.user_means[other_user_id]\n",
    "                )\n",
    "                similarities.append((sim, other_user_id))\n",
    "        \n",
    "        # Get top k neighbors\n",
    "        neighbors = sorted(similarities, reverse=True)[:self.k_neighbors]\n",
    "        \n",
    "        if not neighbors:\n",
    "            return self.user_means.get(user_id, 0)\n",
    "        \n",
    "        # Compute weighted average of neighbors' ratings\n",
    "        numerator = 0\n",
    "        denominator = 0\n",
    "        \n",
    "        for sim, neighbor_id in neighbors:\n",
    "            # Skip if neighbor hasn't rated the item\n",
    "            if item_id not in self.user_ratings[neighbor_id]:\n",
    "                continue\n",
    "                \n",
    "            # Get neighbor's rating and normalize it\n",
    "            neighbor_rating = self.user_ratings[neighbor_id][item_id]\n",
    "            neighbor_mean = self.user_means[neighbor_id]\n",
    "            \n",
    "            numerator += sim * (neighbor_rating - neighbor_mean)\n",
    "            denominator += abs(sim)\n",
    "        \n",
    "        if denominator == 0:\n",
    "            return self.user_means.get(user_id, 0)\n",
    "            \n",
    "        # Return prediction\n",
    "        return self.user_means[user_id] + (numerator / denominator)\n",
    "    \n",
    "    def calculate_metrics(self, true_ratings: List[Tuple[int, int, float]], \n",
    "                         method: str = 'item_based') -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Calculate RMSE and MAE for a set of predictions\n",
    "        \n",
    "        Parameters:\n",
    "        true_ratings: List of tuples (user_id, item_id, rating)\n",
    "        method: 'item_based' or 'user_based'\n",
    "        \n",
    "        Returns:\n",
    "        Dictionary containing RMSE and MAE values\n",
    "        \"\"\"\n",
    "        if not true_ratings:\n",
    "            return {'rmse': 0.0, 'mae': 0.0}\n",
    "            \n",
    "        squared_errors = []\n",
    "        absolute_errors = []\n",
    "        \n",
    "        for user_id, item_id, true_rating in true_ratings:\n",
    "            if method == 'item_based':\n",
    "                pred_rating = self.predict_item_based(user_id, item_id)\n",
    "            else:\n",
    "                pred_rating = self.predict_user_based(user_id, item_id)\n",
    "                \n",
    "            squared_error = (true_rating - pred_rating) ** 2\n",
    "            absolute_error = abs(true_rating - pred_rating)\n",
    "            \n",
    "            squared_errors.append(squared_error)\n",
    "            absolute_errors.append(absolute_error)\n",
    "        \n",
    "        rmse = math.sqrt(np.mean(squared_errors))\n",
    "        mae = np.mean(absolute_errors)\n",
    "        \n",
    "        return {\n",
    "            'rmse': rmse,\n",
    "            'mae': mae\n",
    "        }\n",
    "    \n",
    "    def cross_validate(self, ratings_df: pd.DataFrame, n_splits: int = 5, \n",
    "                      method: str = 'item_based') -> Dict[str, List[float]]:\n",
    "        \"\"\"\n",
    "        Perform k-fold cross-validation\n",
    "        \n",
    "        Parameters:\n",
    "        ratings_df: DataFrame with columns [user_id, item_id, rating]\n",
    "        n_splits: Number of folds for cross-validation\n",
    "        method: 'item_based' or 'user_based'\n",
    "        \n",
    "        Returns:\n",
    "        Dictionary containing lists of RMSE and MAE values for each fold\n",
    "        \"\"\"\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        \n",
    "        rmse_scores = []\n",
    "        mae_scores = []\n",
    "        \n",
    "        # Convert DataFrame to array for easier splitting\n",
    "        ratings_array = ratings_df.values\n",
    "        \n",
    "        for fold_idx, (train_idx, test_idx) in enumerate(kf.split(ratings_array)):\n",
    "            print(f\"Processing fold {fold_idx + 1}/{n_splits}\")\n",
    "            \n",
    "            # Split data into train and test sets\n",
    "            train_data = ratings_array[train_idx]\n",
    "            test_data = ratings_array[test_idx]\n",
    "            \n",
    "            # Convert train data back to DataFrame and fit the model\n",
    "            train_df = pd.DataFrame(train_data, columns=ratings_df.columns)\n",
    "            self.fit(train_df)\n",
    "            \n",
    "            # Calculate metrics for this fold\n",
    "            test_ratings = [(user_id, item_id, rating) \n",
    "                          for user_id, item_id, rating in test_data]\n",
    "            metrics = self.calculate_metrics(test_ratings, method)\n",
    "            \n",
    "            rmse_scores.append(metrics['rmse'])\n",
    "            mae_scores.append(metrics['mae'])\n",
    "        \n",
    "        return {\n",
    "            'rmse_scores': rmse_scores,\n",
    "            'mae_scores': mae_scores,\n",
    "            'mean_rmse': np.mean(rmse_scores),\n",
    "            'std_rmse': np.std(rmse_scores),\n",
    "            'mean_mae': np.mean(mae_scores),\n",
    "            'std_mae': np.std(mae_scores)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Single cross-validation run\n",
    "recommender = SimpleRecommender(k_neighbors=5)\n",
    "cv_results = recommender.cross_validate(ratings_df=df_ratings, n_splits=5, method='item_based')\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_recommender_system(ratings_df: pd.DataFrame, \n",
    "                                methods: List[str] = ['item_based', 'user_based'],\n",
    "                                k_neighbors_list: List[int] = [5, 10, 15],\n",
    "                                n_splits: int = 5) -> Dict:\n",
    "        \"\"\"\n",
    "        Evaluate recommender system with different parameters and methods\n",
    "        \n",
    "        Parameters:\n",
    "        ratings_df: DataFrame with columns [user_id, item_id, rating]\n",
    "        methods: List of methods to evaluate\n",
    "        k_neighbors_list: List of k_neighbors values to try\n",
    "        n_splits: Number of folds for cross-validation\n",
    "        \n",
    "        Returns:\n",
    "        Dictionary containing evaluation results\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        for method in methods:\n",
    "            method_results = {}\n",
    "            for k in k_neighbors_list:\n",
    "                print(f\"\\nEvaluating {method} method with k={k}\")\n",
    "                recommender = SimpleRecommender(k_neighbors=k)\n",
    "                cv_results = recommender.cross_validate(ratings_df=ratings_df, n_splits=n_splits, method=method)\n",
    "                \n",
    "                method_results[k] = {\n",
    "                    'mean_rmse': cv_results['mean_rmse'],\n",
    "                    'std_rmse': cv_results['std_rmse'],\n",
    "                    'mean_mae': cv_results['mean_mae'],\n",
    "                    'std_mae': cv_results['std_mae']\n",
    "                }\n",
    "            \n",
    "            results[method] = method_results\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Comprehensive evaluation of different configurations\n",
    "results = evaluate_recommender_system(\n",
    "    df_ratings,\n",
    "    k_neighbors_list=[5, 10, 15],\n",
    "    n_splits=5\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
